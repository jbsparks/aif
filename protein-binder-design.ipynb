{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# De Novo Protein Design Workflow using NIMs on AIF w/ Jupyter-hub\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example notebook outlines a workflow for creating de novo protein binders using NVIDIA Inference Microservices (NIMs). This workflow leverages advanced AI models to enable computational biologists to design novel protein structures efficiently.\n",
    "\n",
    "The input to this workflow is a protein sequence, which is then fed to AlphaFold2 for structural prediction; alternatively, this can be skipped and a precomputed protein structure (in PDB format) can be used as input. Protein backbones are then generated with RFDiffusion, sequences are generated with ProteinMPNN, and finally complex structures are predicted with AlphaFold2-multimer. \n",
    "\n",
    "This setup provides a powerful framework for exploring protein design, offering flexibility and precision in generating functional protein binders. For more information, refer to the respective repositories and documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started with Demo NIMs\n",
    "\n",
    "This is all performed bu AI-Factory `blueprint`\n",
    "\n",
    "Initial startup of the `AlphaFold NIM` data is time consuming and requires roughly 1.2TB of disk space\n",
    "\n",
    "After AIF NIMS set up is complete, check the status of the four running NIMS e.g with the following commands, remember now we can use the internal service ports and not the public addresses.\n",
    "\n",
    "```bash\n",
    "curl -fsS http://alphafold.protein-binder-design:8081/v1/health/ready\n",
    "curl -fsS http://rfdiffusion.protein-binder-design:8082/v1/health/ready\n",
    "curl -fsS http://proteinmpnn.protein-binder-design:8083/v1/health/ready\n",
    "curl -fsS http://alphafold-multimer.protein-binder-design:8084/v1/health/ready\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -fsS http://alphafold.protein-binder-design:8081/v1/health/ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll install some prerequisites so our examples work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from enum import Enum, StrEnum\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Tuple, Optional, Union\n",
    "import os, requests, json, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One needs to use an NGC Personal Key to run the examples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NVIDIA_API_KEY = os.getenv(\"NVIDIA_API_KEY\") or input(\"Paste Run Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Kubernetes wiring\n",
    "NAMESPACE = \"protein-binder-design\"\n",
    "SERVICES: Dict[str, int] = {\n",
    "    \"alphafold\":          8081,\n",
    "    \"rfdiffusion\":        8082,\n",
    "    \"proteinmpnn\":        8083,\n",
    "    \"alphafold-multimer\": 8084,\n",
    "}\n",
    "SERVICES_BY_PORT = {port: svc for svc, port in SERVICES.items()}\n",
    "\n",
    "def svc_url(service: str, ns: str = NAMESPACE, port: Optional[int] = None, scheme: str = \"http\") -> str:\n",
    "    p = SERVICES[service] if port is None else int(port)\n",
    "    return f\"{scheme}://{service}.{ns}:{p}\"\n",
    "\n",
    "# --- Auth header (optional)\n",
    "HEADERS: Dict[str, str] = {}\n",
    "if (k := os.getenv(\"NGC_API_KEY\")):\n",
    "    HEADERS[\"Authorization\"] = f\"Bearer {k}\"\n",
    "\n",
    "# --- Requests session; ignore any proxy envs inside the pod\n",
    "SESSION = requests.Session()\n",
    "SESSION.trust_env = False\n",
    "\n",
    "# --- Make sure in-cluster names never go through a proxy (harmless if no proxy present)\n",
    "no_proxy = [\n",
    "    \"localhost\",\"127.0.0.1\",\n",
    "    \".svc\",\".svc.cluster.local\",\".cluster.local\",\n",
    "    \"10.0.0.0/8\",\"172.16.0.0/12\",\"192.168.0.0/16\",\n",
    "    \"10.233.0.0/16\",  # adjust if your cluster CIDR differs\n",
    "]\n",
    "no_proxy += [f\"{s}.{NAMESPACE}\" for s in SERVICES]\n",
    "os.environ[\"NO_PROXY\"] = \",\".join(no_proxy)\n",
    "os.environ[\"no_proxy\"] = os.environ[\"NO_PROXY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NIM_PORTS(Enum):\n",
    "    ALPHAFOLD2_PORT  = 8081\n",
    "    RFDIFFUSION_PORT = 8082\n",
    "    PROTEINMPNN_PORT = 8083\n",
    "    AF2_MULTIMER_PORT= 8084\n",
    "\n",
    "class NIM_ENDPOINTS(StrEnum):\n",
    "    ALPHAFOLD2   = \"protein-structure/alphafold2/predict-structure-from-sequence\"\n",
    "    RFDIFFUSION  = \"biology/ipd/rfdiffusion/generate\"\n",
    "    PROTEINMPNN  = \"biology/ipd/proteinmpnn/predict\"\n",
    "    AF2_MULTIMER = \"protein-structure/alphafold2/multimer/predict-structure-from-sequences\"\n",
    "\n",
    "ENDPOINT_TO_SERVICE = {\n",
    "    NIM_ENDPOINTS.ALPHAFOLD2:   \"alphafold\",\n",
    "    NIM_ENDPOINTS.RFDIFFUSION:  \"rfdiffusion\",\n",
    "    NIM_ENDPOINTS.PROTEINMPNN:  \"proteinmpnn\",\n",
    "    NIM_ENDPOINTS.AF2_MULTIMER: \"alphafold-multimer\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Health check (accepts service name, port, or enum)\n",
    "def check_nim_readiness(\n",
    "    target: Union[str, int, NIM_PORTS],\n",
    "    ns: str = NAMESPACE,\n",
    "    ready_path: str = \"/v1/health/ready\",\n",
    "    timeout: int = 5\n",
    ") -> bool:\n",
    "    # normalize to (service, port)\n",
    "    service: Optional[str] = None\n",
    "    port: Optional[int] = None\n",
    "\n",
    "    if isinstance(target, NIM_PORTS):\n",
    "        port = int(target.value)\n",
    "        service = SERVICES_BY_PORT.get(port)\n",
    "    elif isinstance(target, int):\n",
    "        port = target\n",
    "        service = SERVICES_BY_PORT.get(port)\n",
    "    else:\n",
    "        service = str(target)\n",
    "        port = SERVICES.get(service)\n",
    "\n",
    "    if service is None or port is None:\n",
    "        raise ValueError(f\"Unknown service/port: {target}\")\n",
    "\n",
    "    url = f\"{svc_url(service, ns, port=port)}/{ready_path.lstrip('/')}\"\n",
    "    try:\n",
    "        r = SESSION.get(url, headers=HEADERS, timeout=timeout)\n",
    "        return r.ok and r.json().get(\"status\") == \"ready\"\n",
    "    except Exception as e:\n",
    "        print(f\"[readiness:{service}] {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main request helper (cluster-native; supports long jobs + infinite wait)\n",
    "* Uses {service}.{namespace}:{port} automatically.\n",
    "* read_timeout=0 or -1 â‡’ wait forever (like your original code).\n",
    "* For long AF2 jobs, you can either set a very large timeout or keep it infinite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LONG_ENDPOINTS = {NIM_ENDPOINTS.ALPHAFOLD2, NIM_ENDPOINTS.AF2_MULTIMER}\n",
    "\n",
    "def query_nim(payload: Dict[str, Any],\n",
    "              nim_endpoint: NIM_ENDPOINTS | str,\n",
    "              *,\n",
    "              service: Optional[str] = None,\n",
    "              headers: Optional[Dict[str, str]] = None,\n",
    "              ns: str = NAMESPACE,\n",
    "              connect_timeout: int = 5,\n",
    "              read_timeout: Optional[int] = None,   # <=0 => wait forever\n",
    "              echo: bool = False) -> Tuple[int, Dict]:\n",
    "\n",
    "    # normalize endpoint\n",
    "    if isinstance(nim_endpoint, str):\n",
    "        nim_endpoint = NIM_ENDPOINTS(nim_endpoint)\n",
    "\n",
    "    service = service or ENDPOINT_TO_SERVICE[nim_endpoint]\n",
    "    base = svc_url(service, ns)\n",
    "    url  = f\"{base}/{str(nim_endpoint).lstrip('/')}\"\n",
    "\n",
    "    hdrs = dict(HEADERS)\n",
    "    if headers: hdrs.update(headers)\n",
    "\n",
    "    # default read timeout: long for AF2, moderate for others\n",
    "    if read_timeout is None:\n",
    "        read_timeout = 5400 if nim_endpoint in LONG_ENDPOINTS else 900\n",
    "\n",
    "    timeout = None if (isinstance(read_timeout, (int, float)) and read_timeout <= 0) \\\n",
    "              else (connect_timeout, read_timeout)\n",
    "\n",
    "    if echo:\n",
    "        print(\"*\"*80)\n",
    "        print(\"URL:\", url)\n",
    "        print(\"Payload keys:\", list(payload.keys()))\n",
    "        print(f\"Timeouts: {timeout!r}\")  # None => wait forever\n",
    "        print(\"*\"*80)\n",
    "\n",
    "    r = SESSION.post(url, json=payload, headers=hdrs, timeout=timeout)\n",
    "    if r.status_code == 200:\n",
    "        try:\n",
    "            return r.status_code, r.json()\n",
    "        except Exception:\n",
    "            return r.status_code, {\"text\": r.text}\n",
    "    raise Exception(f\"Error {r.status_code}: {r.text[:500]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reduced_pdb(pdb_id: str, rcsb_path: str = None) -> str:\n",
    "    pdb = Path(pdb_id)\n",
    "    if not pdb.exists() and rcsb_path is not None:\n",
    "        pdb.write_text(requests.get(rcsb_path).text)\n",
    "    lines = filter(lambda line: line.startswith(\"ATOM\"), pdb.read_text().split(\"\\n\"))\n",
    "    return \"\\n\".join(list(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleRequestParams:\n",
    "    def __init__(self,\n",
    "                target_sequence: str,\n",
    "                contigs: str, \n",
    "                hotspot_res: List[str],\n",
    "                input_pdb_chains: List[str],\n",
    "                ca_only: bool,\n",
    "                use_soluble_model: bool,\n",
    "                sampling_temp: List[float],\n",
    "                diffusion_steps: int = 15,\n",
    "                num_seq_per_target: int = 20):\n",
    "        self.target_sequence = target_sequence\n",
    "        self.contigs = contigs\n",
    "        self.hotspot_res = hotspot_res\n",
    "        self.input_pdb_chains = input_pdb_chains\n",
    "        self.ca_only = ca_only\n",
    "        self.use_soluble_model = use_soluble_model\n",
    "        self.sampling_temp = sampling_temp\n",
    "        self.diffusion_steps = diffusion_steps\n",
    "        self.num_seq_per_target = num_seq_per_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example data\n",
    "Below, we include three example input sets. Note that these are of varying difficulty and will exhibit different runtimes and resource utilizations.\n",
    "- Example **1R42** should run on most systems with 4 GPUs with 40GB of VRAM or more.\n",
    "- Example **5PTN**\n",
    "- Example **6VXX** requires 4 GPUs with 80GB of VRAM each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_6vxx = ExampleRequestParams(\n",
    "    target_sequence=\"MGILPSPGMPALLSLVSLLSVLLMGCVAETGTQCVNLTTRTQLPPAYTNSFTRGVYYPDKVFRSSVLHSTQDLFLPFFSNVTWFHAIHVSGTNGTKRFDNPVLPFNDGVYFASTEKSNIIRGWIFGTTLDSKTQSLLIVNNATNVVIKVCEFQFCNDPFLGVYYHKNNKSWMESEFRVYSSANNCTFEYVSQPFLMDLEGKQGNFKNLREFVFKNIDGYFKIYSKHTPINLVRDLPQGFSALEPLVDLPIGINITRFQTLLALHRSYLTPGDSSSGWTAGAAAYYVGYLQPRTFLLKYNENGTITDAVDCALDPLSETKCTLKSFTVEKGIYQTSNFRVQPTESIVRFPNITNLCPFGEVFNATRFASVYAWNRKRISNCVADYSVLYNSASFSTFKCYGVSPTKLNDLCFTNVYADSFVIRGDEVRQIAPGQTGKIADYNYKLPDDFTGCVIAWNSNNLDSKVGGNYNYLYRLFRKSNLKPFERDISTEIYQAGSTPCNGVEGFNCYFPLQSYGFQPTNGVGYQPYRVVVLSFELLHAPATVCGPKKSTNLVKNKCVNFNFNGLTGTGVLTESNKKFLPFQQFGRDIADTTDAVRDPQTLEILDITPCSFGGVSVITPGTNTSNQVAVLYQDVNCTEVPVAIHADQLTPTWRVYSTGSNVFQTRAGCLIGAEHVNNSYECDIPIGAGICASYQTQTNSPSGAGSVASQSIIAYTMSLGAENSVAYSNNSIAIPTNFTISVTTEILPVSMTKTSVDCTMYICGDSTECSNLLLQYGSFCTQLNRALTGIAVEQDKNTQEVFAQVKQIYKTPPIKDFGGFNFSQILPDPSKPSKRSFIEDLLFNKVTLADAGFIKQYGDCLGDIAARDLICAQKFNGLTVLPPLLTDEMIAQYTSALLAGTITSGWTFGAGAALQIPFAMQMAYRFNGIGVTQNVLYENQKLIANQFNSAIGKIQDSLSSTASALGKLQDVVNQNAQALNTLVKQLSSNFGAISSVLNDILSRLDPPEAEVQIDRLITGRLQSLQTYVTQQLIRAAEIRASANLAATKMSECVLGQSKRVDFCGKGYHLMSFPQSAPHGVVFLHVTYVPAQEKNFTTAPAICHDGKAHFPREGVFVSNGTHWFVTQRNFYEPQIITTDNTFVSGNCDVVIGIVNNTVYDPLQPELDSFKEELDKYFKNHTSPDVDLGDISGINASVVNIQKEIDRLNEVAKNLNESLIDLQELGKYEQYIKGSGRENLYFQGGGGSGYIPEAPRDGQAYVRKDGEWVLLSTFLGHHHHHHHH\",\n",
    "    contigs=\"A353-410/0 100-200\",\n",
    "    hotspot_res=[\"A360\",\"A361\",\"A362\",\"A366\"],\n",
    "    input_pdb_chains=[\"A\"],\n",
    "    ca_only=False,\n",
    "    use_soluble_model=False,\n",
    "    sampling_temp=[0.1],\n",
    "    diffusion_steps=15,\n",
    "    num_seq_per_target=20\n",
    ")\n",
    "example_5ptn = ExampleRequestParams(\n",
    "    target_sequence=\"NITEEFYQSTCSAVSKGYLSALRTGWYTSVITIELSNIKKIKCNGTDAKIKLIKQELDKYKNAVTELQLLMQSTPATNNQARGSGSGRSLGFLLGVGSAIASGVAVSKVLHLEGEVNKIKSALLSTNKAVVSLSNGVSVLTSKVLDLKNYIDKQLLPIVNKQSCSIPNIETVIEFQQKNNRLLEITREFSVNAGVTTPVSTYMLTNSELLSLINDMPITNDQKKLMSNNVQIVRQQSYSIMSIIKEEVLAYVVQLPLYGVIDTPCWKLHTSPLCTTNTKEGSNICLTRTDRGWYCDNAGSVSFFPQAETCKVQSNRVFCDTMNSLTLPSEVNLCNVDIFNPKYDCKIMTSKTDVSSSVITSLGAIVSCYGKTKCTASNKNRGIIKTFSNGCDYVSNKGVDTVSVGNTLYYVNKQEGKSLYVKGEPIINFYDPLVFPSDQFDASISQVNEKINQSLAFIRKSDELLSAIGGYIPEAPRDGQAYVRKDGEWVLLSTFLGGLVPRGSHHHHHH\",\n",
    "    contigs=\"A1-25/0 70-100\",\n",
    "    hotspot_res=[\"A14\",\"A15\",\"A17\",\"A18\"],\n",
    "    input_pdb_chains=[\"A\"],\n",
    "    ca_only=False,\n",
    "    use_soluble_model=False,\n",
    "    sampling_temp=[0.1],\n",
    "    diffusion_steps=15,\n",
    "    num_seq_per_target=20\n",
    ")\n",
    "example_1r42 = ExampleRequestParams(\n",
    "    target_sequence=\"STIEEQAKTFLDKFNHEAEDLFYQSSLASWNYNTNITEENVQNMNNAGDKWSAFLKEQSTLAQMYPLQEIQNLTVKLQLQALQQNGSSVLSEDKSKRLNTILNTMSTIYSTGKVCNPDNPQECLLLEPGLNEIMANSLDYNERLWAWESWRSEVGKQLRPLYEEYVVLKNEMARANHYEDYGDYWRGDYEVNGVDGYDYSRGQLIEDVEHTFEEIKPLYEHLHAYVRAKLMNAYPSYISPIGCLPAHLLGDMWGRFWTNLYSLTVPFGQKPNIDVTDAMVDQAWDAQRIFKEAEKFFVSVGLPNMTQGFWENSMLTDPGNVQKAVCHPTAWDLGKGDFRILMCTKVTMDDFLTAHHEMGHIQYDMAYAAQPFLLRNGANEGFHEAVGEIMSLSAATPKHLKSIGLLSPDFQEDNETEINFLLKQALTIVGTLPFTYMLEKWRWMVFKGEIPKDQWMKKWWEMKREIVGVVEPVPHDETYCDPASLFHVSNDYSFIRYYTRTLYQFQFQEALCQAAKHEGPLHKCDISNSTEAGQKLFNMLRLGKSEPWTLALENVVGAKNMNVRPLLNYFEPLFTWLKDQNKNSFVGWSTDWSPYAD\",\n",
    "    contigs=\"A114-353/0 50-100\",\n",
    "    hotspot_res=[\"A119\",\"A123\",\"A233\",\"A234\",\"A235\"],\n",
    "    input_pdb_chains=[\"A\"],\n",
    "    ca_only=False,\n",
    "    use_soluble_model=False,\n",
    "    sampling_temp=[0.1],\n",
    "    diffusion_steps=15,\n",
    "    num_seq_per_target=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set the example here to switch example inputs.\n",
    "## Note: Example 6vxx requires a GPU with at least 80GB of VRAM.\n",
    "example = example_5ptn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that the NIM is ready from Python\n",
    "\n",
    "We can test whether each NIM is up and running using our check_nim_readiness function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in (\"alphafold\",\"rfdiffusion\",\"proteinmpnn\",\"alphafold-multimer\"):\n",
    "    print(s, \"ready:\", check_nim_readiness(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaFold2\n",
    "\n",
    "AlphaFold2 is a deep learning model for predicting protein structure from amino acid sequence that has achieved state-of-the-art performance. The NVIDIA AlphaFold2 NIM includes GPU-accelerated MMseqs2, which accelerates the MSA portion of the structural prediction pipeline.\n",
    "\n",
    "**Inputs**:\n",
    "- `sequence`: An amino acid sequence\n",
    "- `algorithm`: The algorithm used for Multiple Sequence Alignment (MSA). This can be either of `jackhmmer` or `mmseqs2`. MMSeqs2 is significantly faster.\n",
    "\n",
    "**Outputs**:\n",
    "- A list of predicted structures in PDB format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "# Estimated 9 minutes on H100 for example 5ptn\n",
    "alphafold2_query = {\n",
    "    \"sequence\": example.target_sequence,\n",
    "    \"algorithm\": \"mmseqs2\",  # if this needs internet, ensure namespace egress allows it\n",
    "}\n",
    "\n",
    "print(f\"[{datetime.now():%Y-%m-%d %H:%M:%S}] start predicted structures in PDB format\")\n",
    "rc, alphafold2_response = query_nim(\n",
    "    payload=alphafold2_query,\n",
    "    nim_endpoint=NIM_ENDPOINTS.ALPHAFOLD2,  # enum, not .value\n",
    "    read_timeout=0,                         # wait forever (or use a big number)\n",
    "    echo=True\n",
    ")\n",
    "print(f\"[{datetime.now():%Y-%m-%d %H:%M:%S}] end predicted structures in PDB format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the first two lines (160 characters) of the alphafold2 response\n",
    "alphafold2_response[0][0:160]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RFDiffusion\n",
    "\n",
    "This section demonstrates how to use RFDiffusion NIM in a *de novo* protein design workflow. Inspired by AI image generation models, RFDiffusion applies generative diffusion techniques to create novel protein structures. It excels in designing complex protein architectures, including binders and symmetric assemblies, by sculpting atomic clouds into functional proteins.\n",
    "\n",
    "**Inputs**\n",
    "- `input_pdb` is the protein target in PDB format\n",
    "- `contigs` is the RFDiffusion language for how to specify regions to work on. See the official [RFDiffusion repo](https://github.com/RosettaCommons/RFdiffusion?tab=readme-ov-file#running-the-diffusion-script) for a full breakdown. A20-60/0 50-100 means to generate a binder to chain A residue 20-60, where the binder is 50-100 residues long. The /0 specifies a chain break.\n",
    "- `hotspot_res` hot spot residues (specifically for binders)\n",
    "- `diffusion_steps` number of diffusion_steps\n",
    "\n",
    "**Output**:\n",
    "- `output_pdb` is the output pdb\n",
    "- `protein` is the input pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Expected runtime: ~15 seconds to 1 minute\n",
    "## H100 runtime: 2 seconds\n",
    "rfdiffusion_query = {\n",
    "        \"input_pdb\" : alphafold2_response[0], ## Take the first structure prediction (of 5) from AlphaFold2\n",
    "        \"contigs\" : \"51-51/A163-181/60-60\", #example.contigs\n",
    "        # \"hotspot_res\" : example.hotspot_res,\n",
    "        \"diffusion_steps\" : example.diffusion_steps\n",
    "    }\n",
    "print(f\"[{datetime.now():%Y-%m-%d %H:%M:%S}] start RFDiffusion generate\")\n",
    "rc, rfdiffusion_response = query_nim(\n",
    "    payload=rfdiffusion_query,\n",
    "    nim_endpoint=NIM_ENDPOINTS.RFDIFFUSION,  # <-- key change\n",
    "    read_timeout=0,                          # wait forever (or set a big number)\n",
    "    echo=True\n",
    ")\n",
    "print(f\"[{datetime.now():%Y-%m-%d %H:%M:%S}] end RFDiffusion -> {rc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print the first 160 characters of the RFDiffusion PDB output\n",
    "print(rfdiffusion_response[\"output_pdb\"][0:160])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ProteinMPNN\n",
    "ProteinMPNN (Protein Message Passing Neural Network) is a deep learning-based graph neural network used in *de novo* protein design workflows. It predicts amino acid sequences for given protein backbones, leveraging evolutionary, functional, and structural information to generate sequences that are likely to fold into the desired 3D structures. This tool integrates seamlessly with NIMs into workflows involving RFDiffusion for backbone generation and AlphaFold-2 Multimer for interaction prediction, enhancing the accuracy and efficiency of protein design.\n",
    "\n",
    "**Inputs**: \n",
    "- `input_pdb` Input protein for which amino acid sequences need to be predicted\n",
    "- `ca_only` Defaults to false, CA-only model helps to address specific needs in protein design where focusing on the alpha carbon (CA)\n",
    "- `use_soluble_model` ProteinMPNN offers soluble models for applications requiring high solubility and non-soluble models for membrane protein studies and industrial applications where solubility is less critical.\n",
    "- `num_seq_per_target` how many seqs to generate for a given target protein structure\n",
    "- `sampling_temp` ranges from 0 to 1 ranges from 0 to 1 and controls the diversity of design outcomes by adjusting the probability values for the 20 amino acids at each sequence position. Higher values increase\n",
    " \n",
    "**Outputs**:\n",
    "- `ProteinMPNN.fa` which is a fasta file containing the generated sequences for the given structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Expected runtime: < 30 seconds for 20 short sequences\n",
    "## H100 Runtime: 5 seconds\n",
    "proteinmpnn_query = {\n",
    "        \"input_pdb\" : rfdiffusion_response[\"output_pdb\"],\n",
    "        \"input_pdb_chains\" : example.input_pdb_chains,\n",
    "        \"ca_only\" : example.ca_only,\n",
    "        \"use_soluble_model\" : example.use_soluble_model,\n",
    "        \"num_seq_per_target\" : example.num_seq_per_target,\n",
    "        \"sampling_temp\" : example.sampling_temp\n",
    "}\n",
    "\n",
    "print(f\"[{datetime.now():%Y-%m-%d %H:%M:%S}] start ProteinMPNN predict\")\n",
    "rc, proteinmpnn_response = query_nim(\n",
    "    payload=proteinmpnn_query,\n",
    "    nim_endpoint=NIM_ENDPOINTS.PROTEINMPNN,  # <-- key change\n",
    "    read_timeout=0,                           # wait indefinitely (or set a big number)\n",
    "    echo=True\n",
    ")\n",
    "print(f\"[{datetime.now():%Y-%m-%d %H:%M:%S}] end ProteinMPNN -> {rc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we'll extract FASTA sequences from the output FASTA file created by ProteinMPNN. Then, we'll create binder-target pairs that we can feed to AlphaFold2-Multimer to predict the binder-target complex structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_sequences = [x.strip() for x in proteinmpnn_response[\"mfasta\"].split(\"\\n\") if '>' not in x][2:]\n",
    "\n",
    "binder_target_pairs = [[binder, example.target_sequence] for binder in fasta_sequences]\n",
    "\n",
    "print(f\"Generated {len(fasta_sequences)} FASTA sequences and {len(binder_target_pairs)} binder-target pairs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AlphaFold2-Multimer\n",
    "\n",
    "AlphaFold2-Multimer is a deep learning model that extends the AlphaFold2 pipelines to predict the combined structure a list of input peptide sequences. \n",
    "\n",
    "**Inputs**:\n",
    "\n",
    "- `sequences`: A list of peptide sequences. For this use case, a single pair of sequences (one peptide chain from the ProteinMPNN result plus the original protein sequence used as input to this workflow).\n",
    "- `algorithm`: The algorithm uses for Multiple Sequence Alignment (MSA). This can be either `jackhmmer` or `mmseqs2`. MMSeqs2 is significantly faster.\n",
    "\n",
    "**Output**:\n",
    "\n",
    "- A list of lists of predicted structures in PDB format. A list of five predictions is returned for each input binder-target pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Expected runtime: 20 min per binder-target pair.\n",
    "## Total runtime: roughly 3 hours\n",
    "\n",
    "from datetime import datetime\n",
    "# sanity: ensure the multimer service is reachable once up front\n",
    "assert check_nim_readiness(\"alphafold-multimer\"), \"alphafold-multimer service not ready\"\n",
    "\n",
    "n_processed = 0\n",
    "multimer_response_codes = [0 for _ in binder_target_pairs]\n",
    "multimer_results = [None for _ in binder_target_pairs]\n",
    "\n",
    "# NOTE: change this to process more or fewer target-binder pairs.\n",
    "pairs_to_process = 1\n",
    "\n",
    "for binder_target_pair in binder_target_pairs:\n",
    "    multimer_query = {\n",
    "        \"sequences\": binder_target_pair,\n",
    "        \"selected_models\": [1],\n",
    "    }\n",
    "    start = datetime.now()\n",
    "    print(f\"[{start:%Y-%m-%d %H:%M:%S}] Processing pair {n_processed+1} of {len(binder_target_pairs)}\")\n",
    "\n",
    "    try:\n",
    "        rc, multimer_response = query_nim(\n",
    "            payload=multimer_query,\n",
    "            nim_endpoint=NIM_ENDPOINTS.AF2_MULTIMER,  # enum (not .value)\n",
    "            read_timeout=0,                            # wait indefinitely; or set big seconds\n",
    "            echo=False\n",
    "        )\n",
    "    except Exception as e:\n",
    "        rc, multimer_response = -1, {\"error\": str(e)}\n",
    "\n",
    "    multimer_response_codes[n_processed] = rc\n",
    "    multimer_results[n_processed] = multimer_response\n",
    "\n",
    "    end = datetime.now()\n",
    "    elapsed = (end - start).total_seconds()\n",
    "    print(f\"[{end:%Y-%m-%d %H:%M:%S}] Finished pair {n_processed+1}/{len(binder_target_pairs)} in {elapsed:.1f}s (rc={rc})\")\n",
    "\n",
    "    n_processed += 1\n",
    "    if n_processed >= pairs_to_process:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print just the first 160 characters of the first multimer response\n",
    "result_idx = 0\n",
    "prediction_idx = 0\n",
    "print(multimer_results[result_idx][prediction_idx][0:160])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing the predicted binders and structures\n",
    "\n",
    "There are many metrics that can be used to assess the quality of the predicted binder-target structure. The predicted local distance difference test (pLDDT) is a measure of per-residue confidence in the local structure. It has a range of zero to one hundred, with higher scores considered more accurate.\n",
    "\n",
    "The following snippet ranks the results of the binder-target pair AlphaFold2-Multimer predictions by their pLDDT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate average pLDDT over all residues \n",
    "def calculate_average_pLDDT(pdb_string):\n",
    "    total_pLDDT = 0.0\n",
    "    atom_count = 0\n",
    "    pdb_lines = pdb_string.splitlines()\n",
    "    for line in pdb_lines:\n",
    "        # PDB atom records start with \"ATOM\"\n",
    "        if line.startswith(\"ATOM\"):\n",
    "            atom_name = line[12:16].strip() # Extract atom name\n",
    "            if atom_name == \"CA\":  # Only consider atoms with name \"CA\"\n",
    "                try:\n",
    "                    # Extract the B-factor value from columns 61-66 (following PDB format specifications)\n",
    "                    pLDDT = float(line[60:66].strip())\n",
    "                    total_pLDDT += pLDDT\n",
    "                    atom_count += 1\n",
    "                except ValueError:\n",
    "                    pass  # Skip lines where B-factor can't be parsed as a float\n",
    "\n",
    "    if atom_count == 0:\n",
    "        return 0.0  # Return 0 if no N atoms were found\n",
    "\n",
    "    average_pLDDT = total_pLDDT / atom_count\n",
    "    return average_pLDDT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plddts = []\n",
    "for idx in range(0, len(multimer_results)):\n",
    "    if multimer_results[idx] is not None:\n",
    "        plddts.append(calculate_average_pLDDT(multimer_results[idx][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine the results with their pLDDTs\n",
    "binder_target_results = list(zip(binder_target_pairs, multimer_results, plddts))\n",
    "\n",
    "## Sort the results by plddt\n",
    "sorted_binder_target_results = sorted(binder_target_results, key=lambda x : x[2])\n",
    "\n",
    "## print the top 5 results\n",
    "for i in range(0, len(sorted_binder_target_results)):\n",
    "    print(\"-\"*80)\n",
    "    print(f\"rank: {i}\")\n",
    "    print(f\"binder: {sorted_binder_target_results[i][0][0]}\")\n",
    "    print(f\"target: {sorted_binder_target_results[i][0][1]}\")\n",
    "    print(f\"pLDDT: {sorted_binder_target_results[i][2]}\")\n",
    "    print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These sequences show the highest pLDDT for their binder-target pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
